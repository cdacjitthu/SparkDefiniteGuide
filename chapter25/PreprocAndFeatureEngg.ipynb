{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    "   .builder \\\n",
    "   .master(\"local[2]\") \\\n",
    "   .appName(\"Preprocessing and Feature Engineering\") \\\n",
    "   .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "sc = spark.sparkContext\n",
    "df = sc.parallelize([\n",
    "    Row(name=\"Alice\", age=30, height=None),\n",
    "    Row(name=\"Bob\", age=None, height=165),\n",
    "    Row(name=None, age=25,  height=180)\n",
    "]).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+-----+\n",
      "| age|height| name|\n",
      "+----+------+-----+\n",
      "|  30|  null|Alice|\n",
      "|null|   165|  Bob|\n",
      "|  25|   180| null|\n",
      "+----+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+-----+\n",
      "| age|height| name|\n",
      "+----+------+-----+\n",
      "|  26|  null|Alice|\n",
      "|null|   165|  Bob|\n",
      "|  25|   180| null|\n",
      "+----+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.replace(30, 26).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+-----+\n",
      "| age|height| name|\n",
      "+----+------+-----+\n",
      "|  30|  null|Alice|\n",
      "|null|   165|  Bob|\n",
      "|  29|   180| null|\n",
      "+----+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.replace(25, 29).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-----+\n",
      "|age|height| name|\n",
      "+---+------+-----+\n",
      "| 30|   170|Alice|\n",
      "| 28|   165|  Bob|\n",
      "| 25|   180|Jilly|\n",
      "+---+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1 = sc.parallelize([\n",
    "    Row(name=\"Alice\", age=30, height=170),\n",
    "    Row(name=\"Bob\", age=28, height=165),\n",
    "    Row(name=\"Jilly\", age=25,  height=180)\n",
    "]).toDF()\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-----+\n",
      "|age|height| name|\n",
      "+---+------+-----+\n",
      "| 26|   170|Alice|\n",
      "| 28|   165|  Bob|\n",
      "| 25|   180|Jilly|\n",
      "+---+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.na.replace(30, 26).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+------+---+------+\n",
      "| name| age|height|age|height|\n",
      "+-----+----+------+---+------+\n",
      "|  Bob|null|   165| 28|   165|\n",
      "|Alice|  30|  null| 30|   170|\n",
      "+-----+----+------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.join(df1, \"name\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+------+----+------+\n",
      "| name|age|height| age|height|\n",
      "+-----+---+------+----+------+\n",
      "|  Bob| 28|   165|null|   165|\n",
      "|Alice| 30|   170|  30|  null|\n",
      "+-----+---+------+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.join(df, \"name\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+------+---+------+\n",
      "| name| age|height|age|height|\n",
      "+-----+----+------+---+------+\n",
      "|  Bob|null|   165| 28|   165|\n",
      "|Alice|  30|  null| 30|   170|\n",
      "+-----+----+------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = df\n",
    "df2.join(df1, \"name\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+------+----+------+\n",
      "| name| age|height| age|height|\n",
      "+-----+----+------+----+------+\n",
      "|  Bob|null|   165|null|   165|\n",
      "|Alice|  30|  null|  30|  null|\n",
      "+-----+----+------+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.join(df, \"name\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|new_height|\n",
      "+----------+\n",
      "|      null|\n",
      "|       164|\n",
      "|       179|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select((df[\"height\"]-1).alias(\"new_height\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|coalesce(name, age)|\n",
      "+-------------------+\n",
      "|              Alice|\n",
      "|                Bob|\n",
      "|                 25|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import coalesce, col\n",
    "df.select(coalesce(col('name'), col('age'))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|coalesce(name)|\n",
      "+--------------+\n",
      "|         Alice|\n",
      "|           Bob|\n",
      "|          null|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(coalesce(col('name'))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-----+\n",
      "|age|height| name|\n",
      "+---+------+-----+\n",
      "| 30|     0|Alice|\n",
      "|  0|   165|  Bob|\n",
      "| 25|   180| null|\n",
      "+---+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(\"John\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-----+\n",
      "|age|height| name|\n",
      "+---+------+-----+\n",
      "| 30|     0|Alice|\n",
      "|  0|   165|  Bob|\n",
      "| 25|   180| John|\n",
      "+---+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|map(name, age)|\n",
      "+--------------+\n",
      "| [Alice -> 30]|\n",
      "|    [Bob -> 0]|\n",
      "|  [John -> 25]|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import create_map, col\n",
    "df.select(create_map(col(\"name\"), col(\"age\"))).alias(\"complex_map\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|  key|value|\n",
      "+-----+-----+\n",
      "|Alice|   30|\n",
      "|  Bob|    0|\n",
      "| John|   25|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import explode\n",
    "df.select(create_map(col(\"name\"), col(\"age\")).alias(\"complex_map\")).selectExpr(\"explode(complex_map)\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formating model according to use case\n",
    "   - In the case of most classification and regression algorithms, you want to get your data into a column of type Double to represent the label and a column of type Vector(either dense or sparse) to represent the features.\n",
    "   - In the case of recommendation, you want to get your data into a column of users, a column of items (say movies or books) and a column of ratings.\n",
    "   - In the case of unsupervised learning, a column of type Vector (either dense or sparse) is needed to represent the features.\n",
    "   - In the case of graph analytics, you will want a dataframe of vertices and a dataframe of edges.\n",
    "### transformers -> pyspark.ml.feature\n",
    "   - Tokenizer is an example of transformer. It tokenizes a string, splitting on a given character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|   580538|    23084|  RABBIT NIGHT LIGHT|      48|2011-12-05 08:38:00|     1.79|   14075.0|United Kingdom|\n",
      "|   580538|    23077| DOUGHNUT LIP GLOSS |      20|2011-12-05 08:38:00|     1.25|   14075.0|United Kingdom|\n",
      "|   580538|    22906|12 MESSAGE CARDS ...|      24|2011-12-05 08:38:00|     1.65|   14075.0|United Kingdom|\n",
      "|   580538|    21914|BLUE HARMONICA IN...|      24|2011-12-05 08:38:00|     1.25|   14075.0|United Kingdom|\n",
      "|   580538|    22467|   GUMBALL COAT RACK|       6|2011-12-05 08:38:00|     2.55|   14075.0|United Kingdom|\n",
      "|   580538|    21544|SKULLS  WATER TRA...|      48|2011-12-05 08:38:00|     0.85|   14075.0|United Kingdom|\n",
      "|   580538|    23126|FELTCRAFT GIRL AM...|       8|2011-12-05 08:38:00|     4.95|   14075.0|United Kingdom|\n",
      "|   580538|    21833|CAMOUFLAGE LED TORCH|      24|2011-12-05 08:38:00|     1.69|   14075.0|United Kingdom|\n",
      "|   580539|    21479|WHITE SKULL HOT W...|       4|2011-12-05 08:39:00|     4.25|   18180.0|United Kingdom|\n",
      "|   580539|   84030E|ENGLISH ROSE HOT ...|       4|2011-12-05 08:39:00|     4.25|   18180.0|United Kingdom|\n",
      "|   580539|    23355|HOT WATER BOTTLE ...|       4|2011-12-05 08:39:00|     4.95|   18180.0|United Kingdom|\n",
      "|   580539|    22111|SCOTTIE DOG HOT W...|       3|2011-12-05 08:39:00|     4.95|   18180.0|United Kingdom|\n",
      "|   580539|    21115|ROSE CARAVAN DOOR...|       8|2011-12-05 08:39:00|     1.95|   18180.0|United Kingdom|\n",
      "|   580539|    21411|GINGHAM HEART  DO...|       8|2011-12-05 08:39:00|     1.95|   18180.0|United Kingdom|\n",
      "|   580539|    23235|STORAGE TIN VINTA...|      12|2011-12-05 08:39:00|     1.25|   18180.0|United Kingdom|\n",
      "|   580539|    23239|SET OF 4 KNICK KN...|       6|2011-12-05 08:39:00|     1.65|   18180.0|United Kingdom|\n",
      "|   580539|    22197|      POPCORN HOLDER|      36|2011-12-05 08:39:00|     0.85|   18180.0|United Kingdom|\n",
      "|   580539|    22693|GROW A FLYTRAP OR...|      24|2011-12-05 08:39:00|     1.25|   18180.0|United Kingdom|\n",
      "|   580539|    22372|AIRLINE BAG VINTA...|       4|2011-12-05 08:39:00|     4.25|   18180.0|United Kingdom|\n",
      "|   580539|    22375|AIRLINE BAG VINTA...|       4|2011-12-05 08:39:00|     4.25|   18180.0|United Kingdom|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales = spark.read.format(\"csv\")\\\n",
    "  .option(\"header\", \"true\")\\\n",
    "  .option(\"inferSchema\", \"true\")\\\n",
    "  .load(\"../data/retail-data/by-day/*.csv\")\\\n",
    "  .where(\"Description IS NOT NULL\")\n",
    "sales.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|   580538|    23084|  RABBIT NIGHT LIGHT|      48|2011-12-05 08:38:00|     1.79|   14075.0|United Kingdom|\n",
      "|   580538|    23077| DOUGHNUT LIP GLOSS |      20|2011-12-05 08:38:00|     1.25|   14075.0|United Kingdom|\n",
      "|   580538|    22906|12 MESSAGE CARDS ...|      24|2011-12-05 08:38:00|     1.65|   14075.0|United Kingdom|\n",
      "|   580538|    21914|BLUE HARMONICA IN...|      24|2011-12-05 08:38:00|     1.25|   14075.0|United Kingdom|\n",
      "|   580538|    22467|   GUMBALL COAT RACK|       6|2011-12-05 08:38:00|     2.55|   14075.0|United Kingdom|\n",
      "|   580538|    21544|SKULLS  WATER TRA...|      48|2011-12-05 08:38:00|     0.85|   14075.0|United Kingdom|\n",
      "|   580538|    23126|FELTCRAFT GIRL AM...|       8|2011-12-05 08:38:00|     4.95|   14075.0|United Kingdom|\n",
      "|   580538|    21833|CAMOUFLAGE LED TORCH|      24|2011-12-05 08:38:00|     1.69|   14075.0|United Kingdom|\n",
      "|   580539|    21479|WHITE SKULL HOT W...|       4|2011-12-05 08:39:00|     4.25|   18180.0|United Kingdom|\n",
      "|   580539|   84030E|ENGLISH ROSE HOT ...|       4|2011-12-05 08:39:00|     4.25|   18180.0|United Kingdom|\n",
      "|   580539|    23355|HOT WATER BOTTLE ...|       4|2011-12-05 08:39:00|     4.95|   18180.0|United Kingdom|\n",
      "|   580539|    22111|SCOTTIE DOG HOT W...|       3|2011-12-05 08:39:00|     4.95|   18180.0|United Kingdom|\n",
      "|   580539|    21115|ROSE CARAVAN DOOR...|       8|2011-12-05 08:39:00|     1.95|   18180.0|United Kingdom|\n",
      "|   580539|    21411|GINGHAM HEART  DO...|       8|2011-12-05 08:39:00|     1.95|   18180.0|United Kingdom|\n",
      "|   580539|    23235|STORAGE TIN VINTA...|      12|2011-12-05 08:39:00|     1.25|   18180.0|United Kingdom|\n",
      "|   580539|    23239|SET OF 4 KNICK KN...|       6|2011-12-05 08:39:00|     1.65|   18180.0|United Kingdom|\n",
      "|   580539|    22197|      POPCORN HOLDER|      36|2011-12-05 08:39:00|     0.85|   18180.0|United Kingdom|\n",
      "|   580539|    22693|GROW A FLYTRAP OR...|      24|2011-12-05 08:39:00|     1.25|   18180.0|United Kingdom|\n",
      "|   580539|    22372|AIRLINE BAG VINTA...|       4|2011-12-05 08:39:00|     4.25|   18180.0|United Kingdom|\n",
      "|   580539|    22375|AIRLINE BAG VINTA...|       4|2011-12-05 08:39:00|     4.25|   18180.0|United Kingdom|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales = spark.read.format(\"csv\")\\\n",
    "  .option(\"header\", \"true\")\\\n",
    "  .option(\"inferSchema\", \"true\")\\\n",
    "  .load(\"../data/retail-data/by-day/*.csv\")\\\n",
    "  .coalesce(5)\\\n",
    "  .where(\"Description IS NOT NULL\")\n",
    "sales.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fakeIntDF = spark.read.parquet(\"../data/simple-ml-integers\")\n",
    "simpleDF = spark.read.json(\"../data/simple-ml\")\n",
    "scaleDF = spark.read.parquet(\"../data/simple-ml-scaling/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|   580538|    23084|  RABBIT NIGHT LIGHT|      48|2011-12-05 08:38:00|     1.79|   14075.0|United Kingdom|\n",
      "|   580538|    23077| DOUGHNUT LIP GLOSS |      20|2011-12-05 08:38:00|     1.25|   14075.0|United Kingdom|\n",
      "|   580538|    22906|12 MESSAGE CARDS ...|      24|2011-12-05 08:38:00|     1.65|   14075.0|United Kingdom|\n",
      "|   580538|    21914|BLUE HARMONICA IN...|      24|2011-12-05 08:38:00|     1.25|   14075.0|United Kingdom|\n",
      "|   580538|    22467|   GUMBALL COAT RACK|       6|2011-12-05 08:38:00|     2.55|   14075.0|United Kingdom|\n",
      "|   580538|    21544|SKULLS  WATER TRA...|      48|2011-12-05 08:38:00|     0.85|   14075.0|United Kingdom|\n",
      "|   580538|    23126|FELTCRAFT GIRL AM...|       8|2011-12-05 08:38:00|     4.95|   14075.0|United Kingdom|\n",
      "|   580538|    21833|CAMOUFLAGE LED TORCH|      24|2011-12-05 08:38:00|     1.69|   14075.0|United Kingdom|\n",
      "|   580539|    21479|WHITE SKULL HOT W...|       4|2011-12-05 08:39:00|     4.25|   18180.0|United Kingdom|\n",
      "|   580539|   84030E|ENGLISH ROSE HOT ...|       4|2011-12-05 08:39:00|     4.25|   18180.0|United Kingdom|\n",
      "|   580539|    23355|HOT WATER BOTTLE ...|       4|2011-12-05 08:39:00|     4.95|   18180.0|United Kingdom|\n",
      "|   580539|    22111|SCOTTIE DOG HOT W...|       3|2011-12-05 08:39:00|     4.95|   18180.0|United Kingdom|\n",
      "|   580539|    21115|ROSE CARAVAN DOOR...|       8|2011-12-05 08:39:00|     1.95|   18180.0|United Kingdom|\n",
      "|   580539|    21411|GINGHAM HEART  DO...|       8|2011-12-05 08:39:00|     1.95|   18180.0|United Kingdom|\n",
      "|   580539|    23235|STORAGE TIN VINTA...|      12|2011-12-05 08:39:00|     1.25|   18180.0|United Kingdom|\n",
      "|   580539|    23239|SET OF 4 KNICK KN...|       6|2011-12-05 08:39:00|     1.65|   18180.0|United Kingdom|\n",
      "|   580539|    22197|      POPCORN HOLDER|      36|2011-12-05 08:39:00|     0.85|   18180.0|United Kingdom|\n",
      "|   580539|    22693|GROW A FLYTRAP OR...|      24|2011-12-05 08:39:00|     1.25|   18180.0|United Kingdom|\n",
      "|   580539|    22372|AIRLINE BAG VINTA...|       4|2011-12-05 08:39:00|     4.25|   18180.0|United Kingdom|\n",
      "|   580539|    22375|AIRLINE BAG VINTA...|       4|2011-12-05 08:39:00|     4.25|   18180.0|United Kingdom|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales.cache()\n",
    "sales.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimator\n",
    " - An estimator is necessary when a transformation you would like to perform must be initialized with data or information about the input column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------+------------------------------------------------------------+\n",
      "|id |features      |StandardScaler_2b31baeb0d76__output                         |\n",
      "+---+--------------+------------------------------------------------------------+\n",
      "|0  |[1.0,0.1,-1.0]|[1.1952286093343936,0.02337622911060922,-0.5976143046671968]|\n",
      "|1  |[2.0,1.1,1.0] |[2.390457218668787,0.2571385202167014,0.5976143046671968]   |\n",
      "|0  |[1.0,0.1,-1.0]|[1.1952286093343936,0.02337622911060922,-0.5976143046671968]|\n",
      "|1  |[2.0,1.1,1.0] |[2.390457218668787,0.2571385202167014,0.5976143046671968]   |\n",
      "|1  |[3.0,10.1,3.0]|[3.5856858280031805,2.3609991401715313,1.7928429140015902]  |\n",
      "+---+--------------+------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Tokenizer, StandardScaler\n",
    "ss = StandardScaler(inputCol=\"features\")\n",
    "ss.fit(scaleDF).transform(scaleDF).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------+\n",
      "| id|      features|\n",
      "+---+--------------+\n",
      "|  0|[1.0,0.1,-1.0]|\n",
      "|  1| [2.0,1.1,1.0]|\n",
      "|  0|[1.0,0.1,-1.0]|\n",
      "|  1| [2.0,1.1,1.0]|\n",
      "|  1|[3.0,10.1,3.0]|\n",
      "+---+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaleDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------+------------------------------------------+\n",
      "|Description                        |Tokenizer_d90ddc64c435__output            |\n",
      "+-----------------------------------+------------------------------------------+\n",
      "|RABBIT NIGHT LIGHT                 |[rabbit, night, light]                    |\n",
      "|DOUGHNUT LIP GLOSS                 |[doughnut, lip, gloss]                    |\n",
      "|12 MESSAGE CARDS WITH ENVELOPES    |[12, message, cards, with, envelopes]     |\n",
      "|BLUE HARMONICA IN BOX              |[blue, harmonica, in, box]                |\n",
      "|GUMBALL COAT RACK                  |[gumball, coat, rack]                     |\n",
      "|SKULLS  WATER TRANSFER TATTOOS     |[skulls, , water, transfer, tattoos]      |\n",
      "|FELTCRAFT GIRL AMELIE KIT          |[feltcraft, girl, amelie, kit]            |\n",
      "|CAMOUFLAGE LED TORCH               |[camouflage, led, torch]                  |\n",
      "|WHITE SKULL HOT WATER BOTTLE       |[white, skull, hot, water, bottle]        |\n",
      "|ENGLISH ROSE HOT WATER BOTTLE      |[english, rose, hot, water, bottle]       |\n",
      "|HOT WATER BOTTLE KEEP CALM         |[hot, water, bottle, keep, calm]          |\n",
      "|SCOTTIE DOG HOT WATER BOTTLE       |[scottie, dog, hot, water, bottle]        |\n",
      "|ROSE CARAVAN DOORSTOP              |[rose, caravan, doorstop]                 |\n",
      "|GINGHAM HEART  DOORSTOP RED        |[gingham, heart, , doorstop, red]         |\n",
      "|STORAGE TIN VINTAGE LEAF           |[storage, tin, vintage, leaf]             |\n",
      "|SET OF 4 KNICK KNACK TINS POPPIES  |[set, of, 4, knick, knack, tins, poppies] |\n",
      "|POPCORN HOLDER                     |[popcorn, holder]                         |\n",
      "|GROW A FLYTRAP OR SUNFLOWER IN TIN |[grow, a, flytrap, or, sunflower, in, tin]|\n",
      "|AIRLINE BAG VINTAGE WORLD CHAMPION |[airline, bag, vintage, world, champion]  |\n",
      "|AIRLINE BAG VINTAGE JET SET BROWN  |[airline, bag, vintage, jet, set, brown]  |\n",
      "+-----------------------------------+------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Tokenizer(inputCol=\"Description\").transform(sales.select(\"Description\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------+\n",
      "|split(Description,  )                     |\n",
      "+------------------------------------------+\n",
      "|[RABBIT, NIGHT, LIGHT]                    |\n",
      "|[DOUGHNUT, LIP, GLOSS, ]                  |\n",
      "|[12, MESSAGE, CARDS, WITH, ENVELOPES]     |\n",
      "|[BLUE, HARMONICA, IN, BOX, ]              |\n",
      "|[GUMBALL, COAT, RACK]                     |\n",
      "|[SKULLS, , WATER, TRANSFER, TATTOOS, ]    |\n",
      "|[FELTCRAFT, GIRL, AMELIE, KIT]            |\n",
      "|[CAMOUFLAGE, LED, TORCH]                  |\n",
      "|[WHITE, SKULL, HOT, WATER, BOTTLE, ]      |\n",
      "|[ENGLISH, ROSE, HOT, WATER, BOTTLE]       |\n",
      "|[HOT, WATER, BOTTLE, KEEP, CALM]          |\n",
      "|[SCOTTIE, DOG, HOT, WATER, BOTTLE]        |\n",
      "|[ROSE, CARAVAN, DOORSTOP]                 |\n",
      "|[GINGHAM, HEART, , DOORSTOP, RED]         |\n",
      "|[STORAGE, TIN, VINTAGE, LEAF]             |\n",
      "|[SET, OF, 4, KNICK, KNACK, TINS, POPPIES] |\n",
      "|[POPCORN, HOLDER]                         |\n",
      "|[GROW, A, FLYTRAP, OR, SUNFLOWER, IN, TIN]|\n",
      "|[AIRLINE, BAG, VINTAGE, WORLD, CHAMPION, ]|\n",
      "|[AIRLINE, BAG, VINTAGE, JET, SET, BROWN]  |\n",
      "+------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import split, col\n",
    "sales.select(split(col(\"Description\"), \" \")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High-Level Transformers\n",
    " - High level transformers, Rformula allows to concisely specify a number of transformations is one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+------+------------------+\n",
      "|color| lab|value1|            value2|\n",
      "+-----+----+------+------------------+\n",
      "|green|good|     1|14.386294994851129|\n",
      "| blue| bad|     8|14.386294994851129|\n",
      "| blue| bad|    12|14.386294994851129|\n",
      "|green|good|    15| 38.97187133755819|\n",
      "|green|good|    12|14.386294994851129|\n",
      "+-----+----+------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "simpleDF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+------+------------------+--------------------------------------------------------------------+-----+\n",
      "|color|lab |value1|value2            |features                                                            |label|\n",
      "+-----+----+------+------------------+--------------------------------------------------------------------+-----+\n",
      "|green|good|1     |14.386294994851129|(10,[1,2,3,5,8],[1.0,1.0,14.386294994851129,1.0,14.386294994851129])|1.0  |\n",
      "|blue |bad |8     |14.386294994851129|(10,[2,3,6,9],[8.0,14.386294994851129,8.0,14.386294994851129])      |0.0  |\n",
      "|blue |bad |12    |14.386294994851129|(10,[2,3,6,9],[12.0,14.386294994851129,12.0,14.386294994851129])    |0.0  |\n",
      "+-----+----+------+------------------+--------------------------------------------------------------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import RFormula\n",
    "supervised = RFormula(formula=\"lab ~.+ color:value1 + color:value2\")\n",
    "supervised.fit(simpleDF).transform(simpleDF).show(3, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+----------+\n",
      "|sum(Quantity)|count(1)|CustomerID|\n",
      "+-------------+--------+----------+\n",
      "|       283171|  133626|      null|\n",
      "|            0|       2|   12346.0|\n",
      "|         2458|     182|   12347.0|\n",
      "|         2341|      31|   12348.0|\n",
      "|          631|      73|   12349.0|\n",
      "|          197|      17|   12350.0|\n",
      "|          470|      95|   12352.0|\n",
      "|           20|       4|   12353.0|\n",
      "|          530|      58|   12354.0|\n",
      "|          240|      13|   12355.0|\n",
      "|         1591|      59|   12356.0|\n",
      "|         2708|     131|   12357.0|\n",
      "|          248|      19|   12358.0|\n",
      "|         1612|     254|   12359.0|\n",
      "|         1165|     129|   12360.0|\n",
      "|           91|      10|   12361.0|\n",
      "|         2212|     274|   12362.0|\n",
      "|          408|      23|   12363.0|\n",
      "|         1506|      85|   12364.0|\n",
      "|          173|      23|   12365.0|\n",
      "+-------------+--------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import SQLTransformer\n",
    "basicTransformation = SQLTransformer() \\\n",
    "    .setStatement(\"\"\"\n",
    "    SELECT sum(Quantity), count(*), CustomerID\n",
    "    FROM __THIS__\n",
    "    GROUP BY CustomerID\n",
    "    ORDER BY CustomerID\n",
    "    \"\"\")\n",
    "basicTransformation.transform(sales).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VectorAssembler\n",
    " - it will be used in nearly every single pipeline you generate. It helps concatenate all features into one big vector you can then pass into an estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+\n",
      "|int1|int2|int3|\n",
      "+----+----+----+\n",
      "|   7|   8|   9|\n",
      "|   4|   5|   6|\n",
      "|   1|   2|   3|\n",
      "+----+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fakeIntDF.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+------------------------------------+\n",
      "|int1|int2|int3|VectorAssembler_bf236edce483__output|\n",
      "+----+----+----+------------------------------------+\n",
      "|   7|   8|   9|                       [7.0,8.0,9.0]|\n",
      "|   4|   5|   6|                       [4.0,5.0,6.0]|\n",
      "|   1|   2|   3|                       [1.0,2.0,3.0]|\n",
      "+----+----+----+------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "va = VectorAssembler().setInputCols([\"int1\", \"int2\", \"int3\"])\n",
    "va.transform(fakeIntDF).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with continuous variables\n",
    " - Continuous features are values from -Infinite to +/Infinite\n",
    "    - Convert continuous features into categorical features vis a process called bucketing.\n",
    "    - can be scaled and normalized features.\n",
    "    - Transformers will only work on Double Types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The following three conditions are to be met in bucketing split\n",
    "  - The minimum value in your splits array must be less than the minimum value in dataFrame.\n",
    "  - The maximum value in your splits array must be greater than the maximum value in dataFrame.\n",
    "  - You need to specify at a minimum three values in the split array, which creates two buckets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
